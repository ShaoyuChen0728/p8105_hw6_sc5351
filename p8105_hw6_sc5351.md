p8105_hw6_sc5351
================
Shaoyu Chen

``` r
library(tidyverse)
library(modelr)
```

### Problem 1

# Create a city_state variable (e.g. “Baltimore, MD”), and a binary variable indicating whether the homicide is solved. Omit cities Dallas, TX; Phoenix, AZ; and Kansas City, MO – these don’t report victim race. Also omit Tulsa, AL – this is a data entry mistake. For this problem, limit your analysis those for whom victim_race is white or black. Be sure that victim_age is numeric.

``` r
homicide_df = 
  read_csv("./data/homicide-data.csv", na = c("", "NA", "Unknown")) |> 
  mutate(
    city_state = str_c(city, state, sep = ", "),
    victim_age = as.numeric(victim_age),
    resolution = case_when(
      disposition == "Closed without arrest" ~ 0,
      disposition == "Open/No arrest"        ~ 0,
      disposition == "Closed by arrest"      ~ 1)
  ) |> 
  filter(victim_race %in% c("White", "Black")) |> 
  filter(!(city_state %in% c("Tulsa, AL", "Dallas, TX", "Phoenix, AZ", "Kansas City, MO"))) |> 
  select(city_state, resolution, victim_age, victim_sex, victim_race)
```

    ## Rows: 52179 Columns: 12
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (8): uid, victim_last, victim_first, victim_race, victim_sex, city, stat...
    ## dbl (4): reported_date, victim_age, lat, lon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

# For the city of Baltimore, MD, use the glm function to fit a logistic regression with resolved vs unresolved as the outcome and victim age, sex and race as predictors. Save the output of glm as an R object; apply the broom::tidy to this object; and obtain the estimate and confidence interval of the adjusted odds ratio for solving homicides comparing male victims to female victims keeping all other variables fixed.

``` r
baltimore_glm = 
  filter(homicide_df, city_state == "Baltimore, MD") |> 
  glm(resolution ~ victim_age + victim_sex + victim_race, family = binomial(), data = _)

baltimore_glm |> 
  broom::tidy() |> 
  mutate(
    OR = exp(estimate), 
    OR_CI_upper = exp(estimate + 1.96 * std.error),
    OR_CI_lower = exp(estimate - 1.96 * std.error)) |> 
  filter(term == "victim_sexMale") |> 
  select(OR, OR_CI_lower, OR_CI_upper) |>
  knitr::kable(digits = 3)
```

|    OR | OR_CI_lower | OR_CI_upper |
|------:|------------:|------------:|
| 0.426 |       0.325 |       0.558 |

# Now run glm for each of the cities in your dataset, and extract the adjusted odds ratio (and CI) for solving homicides comparing male victims to female victims. Do this within a “tidy” pipeline, making use of purrr::map, list columns, and unnest as necessary to create a dataframe with estimated ORs and CIs for each city.

``` r
model_results = 
  homicide_df |> 
  nest(data = -city_state) |> 
  mutate(
    models = map(data, \(df) glm(resolution ~ victim_age + victim_sex + victim_race, 
                             family = binomial(), data = df)),
    tidy_models = map(models, broom::tidy)) |> 
  select(-models, -data) |> 
  unnest(cols = tidy_models) |> 
  mutate(
    OR = exp(estimate), 
    OR_CI_upper = exp(estimate + 1.96 * std.error),
    OR_CI_lower = exp(estimate - 1.96 * std.error)) |> 
  filter(term == "victim_sexMale") |> 
  select(city_state, OR, OR_CI_lower, OR_CI_upper)

model_results |>
  slice(1:5) |> 
  knitr::kable(digits = 3)
```

| city_state      |    OR | OR_CI_lower | OR_CI_upper |
|:----------------|------:|------------:|------------:|
| Albuquerque, NM | 1.767 |       0.831 |       3.761 |
| Atlanta, GA     | 1.000 |       0.684 |       1.463 |
| Baltimore, MD   | 0.426 |       0.325 |       0.558 |
| Baton Rouge, LA | 0.381 |       0.209 |       0.695 |
| Birmingham, AL  | 0.870 |       0.574 |       1.318 |

# Create a plot that shows the estimated ORs and CIs for each city. Organize cities according to estimated OR, and comment on the plot.

``` r
model_results |> 
  mutate(city_state = fct_reorder(city_state, OR)) |> 
  ggplot(aes(x = city_state, y = OR)) + 
  geom_point() + 
  geom_errorbar(aes(ymin = OR_CI_lower, ymax = OR_CI_upper)) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

<img src="p8105_hw6_sc5351_files/figure-gfm/q1_plot-1.png" width="90%" />

### Problem 2

\#First,download the weather data.

``` r
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2022-01-01",
    date_max = "2022-12-31") |>
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) |>
  select(name, id, everything())
```

    ## using cached file: /Users/chenshaoyu/Library/Caches/org.R-project.R/R/rnoaa/noaa_ghcnd/USW00094728.dly

    ## date created (size, mb): 2023-12-02 18:06:24.70211 (8.544)

    ## file min/max dates: 1869-01-01 / 2023-11-30

\#Create bootstrap function

``` r
boot_sample = function(df) {
  
  sample_frac(df, replace = TRUE)
  
}
```

\#Use 5000 bootstrap samples and, for each bootstrap sample, produce
estimates of rsquare

``` r
boot_data = 
  weather_df |> 
  modelr::bootstrap(n = 5000) |>
  mutate(
    models = map(strap, \(df) lm(tmax ~ tmin + prcp, data = df)),
    results = map(models, broom::tidy),
    glance = map(models, broom::glance))|>
  select(-strap,-models)|>
  unnest(glance,results)
boot_data
```

    ## # A tibble: 15,000 × 18
    ##    .id   term     estimate std.error statistic   p.value r.squared adj.r.squared
    ##    <chr> <chr>       <dbl>     <dbl>     <dbl>     <dbl>     <dbl>         <dbl>
    ##  1 0001  (Interc…  8.50      0.241       35.3  2.30e-119     0.898         0.898
    ##  2 0001  tmin      0.972     0.0172      56.6  8.29e-182     0.898         0.898
    ##  3 0001  prcp      0.00449   0.00211      2.12 3.46e-  2     0.898         0.898
    ##  4 0002  (Interc…  7.99      0.207       38.6  2.90e-130     0.928         0.928
    ##  5 0002  tmin      1.02      0.0149      68.4  4.78e-209     0.928         0.928
    ##  6 0002  prcp     -0.00702   0.00198     -3.55 4.35e-  4     0.928         0.928
    ##  7 0003  (Interc…  8.10      0.209       38.7  7.88e-131     0.925         0.925
    ##  8 0003  tmin      1.03      0.0154      66.9  8.45e-206     0.925         0.925
    ##  9 0003  prcp     -0.00776   0.00177     -4.38 1.58e-  5     0.925         0.925
    ## 10 0004  (Interc…  8.18      0.202       40.6  9.96e-137     0.931         0.931
    ## # ℹ 14,990 more rows
    ## # ℹ 10 more variables: sigma <dbl>, statistic1 <dbl>, p.value1 <dbl>, df <dbl>,
    ## #   logLik <dbl>, AIC <dbl>, BIC <dbl>, deviance <dbl>, df.residual <int>,
    ## #   nobs <int>

\#Plot the distribution of rsquare

``` r
r_plot =
  boot_data|>
  ggplot(aes(x = r.squared)) +
  geom_density()
r_plot
```

<img src="p8105_hw6_sc5351_files/figure-gfm/unnamed-chunk-4-1.png" width="90%" />
The plot is a slightly left-skewed of R-squared, and the peak of the
density is around 0.92.

\#construct 95% confidence interval of rsquare.

``` r
r_squared_ci = 
  boot_data %>%
  select(r.squared) %>%
  summarize(
    ci_lower = quantile(r.squared, 0.025),
    ci_upper = quantile(r.squared, 0.975)
  )

r_squared_ci
```

    ## # A tibble: 1 × 2
    ##   ci_lower ci_upper
    ##      <dbl>    <dbl>
    ## 1    0.889    0.941

A 95% confidence interval for the rsquared is between 0.889 and 0.941.

\#Use 5000 bootstrap samples and, for each bootstrap sample, produce
estimates of log(beta1\*beta2).
